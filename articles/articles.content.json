
{
    "articles":[
		{
            "title": "The Math inside Neural Networks",
            "description": "Neural Networks are universal function approximators - but how exactly? We look at the math that makes them work.",
            "img": "https://victorzhou.com/media/nn-series/network.svg",
            "link": "the_math_inside_neural_networks",
            "date": "06 July 2021",
            "time": "10 mins",
            "elements": [
                {
                    "type": "text",
                    "content": "This article is intended for those who have an undergraduate level understanding of linear algebra, calculus, as well as some introductory knowledge of vanilla neural neworks. I've tried my best to keep things simple without turning this into an 'Introduction to Neural Networks' article."
                },
                {
                    "type": "heading",
                    "content": "I. Introduction"
                },
                {
                    "type": "text",
                    "content": "There are three primary processes that go on inside a vanilla multilayered neural network in a supervised learning setup:"
                },
                {
                    "type": "text",
                    "content": "1. Feedforward - The network guesses an answer that is almost always incorrect."
                },
                {
                    "type": "text",
                    "content": "2. Error Calculation - The network calculates the amount of error between it's answer and the correct answer."
                },
                {
                    "type": "text",
                    "content": "3. Backpropagation - The network updates it's parameters (or weights) to minimise the error."
                },
                {
                    "type": "text",
                    "content": "We will analyse the mathematics of all three of these processes in order to reach an understanding of the overall system."
                },
                {
                    "type": "heading",
                    "content": "II. Feedforward"
                },
                {
                    "type": "text",
                    "content": "A neural network converts a vector X in an input space Rx to a vector Y in an output space Ry. Since a vector is being transformed from one space to another, we know a matrix is involved. This matrix is actually the weights of that particular layer. Thus, each layer after the input layer represents a vector transformation with a corresponding weight matrix."
                },
                {
                    "type": "text",
                    "content": "We take a closer look by analysing the set of operations inside the first hidden layer. Let's say the input layer has a total 'N' number of neurons and the first hidden layer has a total 'M' number of neurons."
                },
                {
                    "type": "image",
                    "content": "https://i.imgur.com/HesefMW.jpg"
                },
                {
                    "type": "text",
                    "content": "Mathematically, this is just standard matrix multiplication:"
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/gLxc3F2.png"
                },
                {
                    "type": "text",
                    "content": "We now have a system that converts vectors from one vector space to another. If this was the only operation in each layer, the entire neural network could be represented as a single weight matrix by post-multiplying the weight matrices of each layer. Of course, that is not what happens!"
                },
                {
                    "type": "text",
                    "content": "The reason we have multiple layers in the network is because each layer has an activation function. An activation function squishes the outputs of a layer into a certain range. Because there are no restrictions on how large the values inside X or W can be, after a few multiplications the magnitude of values inside H can increase to the point where computers run out of space to store those values. Besides, we dont need very large values for tasks like classification or probabilistic prediction."
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/8bzOMFJ.png"
                },
                {
                    "type": "text",
                    "content": "We thus obtain the final activation values of the first layer after passing H through an activation function. Generally, we want the following characteristics in an activation function:"
                },
                {
                    "type": "text",
                    "content": "(i) It should be monotonic increasing (in other words, an increase in h should result in an increase in a)."
                },
                {
                    "type": "text",
                    "content": "(ii) It should be bounded to a certain interval. This could either be a lower bound, upper bound, or both."
                },
                {
                    "type": "text",
                    "content": "(iii) It should be differentiable. We will discuss why this is important during backpropagation."
                },
                {
                    "type": "text",
                    "content": "Two functions that fit this requirement are the sigmoid function and the tanh function. Of course, there are more activation functions for other use cases but let's consider these two for now. The graph below shows us how these functions constrain the input. The sigmoid function is in blue and the tanh function is in green."
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/BWKz3oU.png"
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/rVh6kLf.png"
                },
                {
                    "type": "text",
                    "content": "This process of weight multiplication followed by activation is repeated for each layer, till we reach the final layer. If we want to express this in form of pseudocode, we can do it as follows :"
                },
                {
                    "type": "image",
                    "content": "https://i.imgur.com/3aFaYnJ.png"
                },
                {
                    "type": "text",
                    "content": "The layers include the output layer of the network. This means at the end of the forward pass we have the output of the entire network. The number of elements in the output will be equal to the number of neurons in the output layer. At this point our network has guessed an answer, which is most likley wrong since it is an untrained network. Up next, we will describe how the network quantifies it's error."
                },
                {
                    "type": "heading",
                    "content": "III. Error Calculation"
                },
                {
                    "type": "text",
                    "content": "In supervised learning we have labelled outputs for our inputs during training. We call these labels 'targets'. To calculate the error in the network's output Y we need to compare it to the corresponding target T. But how exactly do we determine the error. Do we simply subtract Y from T?"
                },
                {
                    "type": "text",
                    "content": "Whatever the error is, we ideally want to minimise it. Error is also referred to as the 'Loss' of the network. Whatever this loss function is, it should be as low as possible for maximum accuracy of the network. Let us plot the target T and the output Y on a graph."
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/lBw87fp.png"
                },
                {
                    "type": "text",
                    "content": "The red line on the graph denotes y = t, which is the optimal condition. The blue point denotes any point (y0,t0) for any input x0. What we really want is to minimise the distance between the line (y = t) and the point (y0,t0). This gives us a good starting point for defining the loss function."
                },
                {
                    "type": "text",
                    "content": "The distance between any point (y0,t0) and the line (y=t) can be described using the formula: "
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/rdB6LnB.png"
                },
                {
                    "type": "text",
                    "content": "To minimise d, we minimise |y0 - t0|. Assuming there are K elements in the output layer, we define the loss function E as:"
                },
                {
                    "type": "latex",
                    "content": "https://imgur.com/xvxPnxT.png"
                },
                {
                    "type": "text",
                    "content": "We have described E mathematically. That's nice, but we took all this trouble to answer the question - How much should the weights of the network be adjusted in a way that reduces E? Introducing Backpropagation."
                },
                {
                    "type": "heading",
                    "content": "IV. Backpropagation"
                },
                {
                    "type": "text",
                    "content": "Before we adjust the weights of the entire network, we need to determine the error for each layer. The loss function E denotes the error for the network, that's true. But more specifically, it is the error of the output layer."
                },
                {
                    "type": "text",
                    "content": "Backpropagation is a popular approach to solve this problem. Starting from the output layer, the error propagates backwards until the weights of all layers have been updated. Let us first look at how we update the weights in the output layer."
                },
                {
                    "type": "text",
                    "content": "To do that we first express E as a function of the weights of the output layer. If Wyz denotes the weight matrix of the output layer, and A denotes the activations of the second last layer:"
                },
                {
                    "type": "image",
                    "content": "https://i.imgur.com/JBV4Qh6.jpg"
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/MA3cPuy.png"
                },
                {
                    "type": "text",
                    "content": "Next we calculate the gradient of E with respect to Wyz using the chain rule:"
                },
                {
                    "type":"latex",
                    "content": "https://i.imgur.com/F2All1f.png"
                },
                {
                    "type": "text",
                    "content": "We can resolve these three terms individually very easily. Let's start with dE/dY: "
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/ONgRnBR.png"
                },
                {
                    "type": "text",
                    "content": "To calculate dY/dZ, recall that Y=f(Z) where f is the activation function. This is why we insist on having a differentiable activation function."
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/DYhpTyI.png"
                },
                {
                    "type": "text",
                    "content": "We have a trick to quickly compute the derivates. The derivatives of the sigmoid and tanh functions can be represented as follows:"
                },
                {
                    "type": "latex",
                    "content": "https://imgur.com/KBcafpB.png"
                },
                {
                    "type": "text",
                    "content": "dZ/dWyz is actually just Ay"
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/P7zWOlf.png"
                },
                {
                    "type": "text",
                    "content": "We can rewrite the dE/dWyz as:"
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/6YoMFSV.png"
                },
                {
                    "type": "text",
                    "content": "We can also determine the gradient for each connection Wij in the matrix Wyz. Also note that we can safely ignore the '2' in the equation because we are not concerned with the coefficients."
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/cUTrxzC.png"
                },
                {
                    "type": "text",
                    "content": "Thus the new value of any connection Wij in the matrix Wyz is written as follow. The symbol gamma (r) represents the learning rate and accounts of all coefficients. This is also why we discarded the '2' previously."
                },
                {
                    "type": "latex",
                    "content": "https://imgur.com/8fLVZmb.png"
                },
                {
                    "type": "text",
                    "content": "We saw how a given weight Wij in the output layer can be updated. But to understand backpropagation for hidden layers we need to understand the matrices at play. In order to satisfy the dimensionality of the vectors, we take the transpose on the RHS and rewrite the matrix equation as follows:"
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/YDoLdoD.png"
                },
                {
                    "type": "text",
                    "content": "Here Dz is a ZxZ diagonal matrix containing the derivatives of the output activations."
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/ss2H2sC.png"
                },
                {
                    "type": "text",
                    "content": "This is how computers calculate gradients. We finally calculate the gradients for the hidden layer with the weight matrix Wxy."
                },
                {
                    "type": "latex",
                    "content": "https://i.imgur.com/rp11Btv.png"
                },
                {
                    "type": "text",
                    "content": "The above process is repeated for the previous layers until we finally update the weights of the first hidden layer. Backpropagation can be summarised by pseudocode as follows:"
                },
                {
                    "type": "image",
                    "content": "https://i.imgur.com/dDrO2DY.png"
                },
                {
                    "type": "heading",
                    "content": "V. Conclusion"
                },
                {
                    "type": "text",
                    "content": "We discussed how neural networks are carefully coordinated matrix operations. If you found this article useful and want to study the concepts behind Neural Networks in detail, you may read 'Neural Networks - A Systemic Introduction' by Raul Rojas."
                }
            ]
        }
    ]
}
